{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2c96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col,max,count,sum,mean,stddev_pop,hour,countDistinct,expr,stddev,window,column\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569ab09",
   "metadata": {},
   "source": [
    "# Assignment # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72919ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/21 19:37:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# sc.stop()\n",
    "\n",
    "# Initialization of SparkConf which is required for Spark Context\n",
    "conf = SparkConf().setAppName('myapp').setMaster('local')\n",
    "\n",
    "# Initialization of SparkContext\n",
    "sc = SparkContext().getOrCreate(conf=conf)\n",
    "sc.setLogLevel(\"OFF\")\n",
    "\n",
    "# Initialization of SparkSession into spark variable\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02400b",
   "metadata": {},
   "source": [
    "### How to read a text file in pyspark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bc9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('a_text_file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f8cf37",
   "metadata": {},
   "source": [
    "### which options are correct to split rdd containing string type data in pyspark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612dd62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'world',\n",
       " 'lol',\n",
       " 'Yellow',\n",
       " 'world',\n",
       " 'lol',\n",
       " 'Hello',\n",
       " 'world',\n",
       " 'lol',\n",
       " 'Hello',\n",
       " 'world',\n",
       " 'lol',\n",
       " 'Hello',\n",
       " 'world',\n",
       " 'lol',\n",
       " 'Hello',\n",
       " 'world',\n",
       " 'lol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.flatMap(lambda line: line.split(\" \"))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093be022",
   "metadata": {},
   "source": [
    "### Identify the mistake in the given code and drop the correct left item into right catagory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28890f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big Data', 'a', 'b'),\n",
       " ('Data Science', 'a', 'b'),\n",
       " ('Intro to Web', 'a', 'b'),\n",
       " ('Web Engineering', 'a', 'b'),\n",
       " ('Network Theory', 'a', 'b'),\n",
       " ('Machine Learning', 'a', 'b')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sc.parallelize ([\n",
    "\"Big Data\",\n",
    "\"Data Science\",\n",
    "\"Intro to Web\",\n",
    "\"Web Engineering\",\n",
    "\"Network Theory\",\n",
    "\"Machine Learning\",\n",
    "])\n",
    "\n",
    "words_map = words.map(lambda x: (x, \"a\", \"b\"))\n",
    "# words_map = words.map(lambda x: (x, \"a\"))\n",
    "words_map.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc9ec7",
   "metadata": {},
   "source": [
    "### What would be the output of this code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588f9038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Data', 'Data Science']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sc.parallelize([\"Big Data\", \"Data Science\", \"Intro to Web\",  \"Web Engineering\",  \"Network Theory\", \"Machine Learning\", ])\n",
    "words_map = words.filter(lambda x: \"Data\" in x)\n",
    "words_map.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446b348",
   "metadata": {},
   "source": [
    "### Reading CSV file from the same folder where this notebook file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bffcf139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DEST_COUNTRY_NAME', 'string'),\n",
       " ('ORIGIN_COUNTRY_NAME', 'string'),\n",
       " ('count', 'int')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('summary.csv', inferSchema=True, header=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8d389",
   "metadata": {},
   "source": [
    "### Find the maximum number of flights from Origin country to Destination country by reading flightdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd61a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Max Flights|\n",
      "+-----------+\n",
      "|     370002|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(col('count')).alias('Max Flights')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b18428",
   "metadata": {},
   "source": [
    "### Count those rows where number of flights going from Origin country to Destination country are greater than 10 by reading flightdata again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5d62d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|haha|\n",
      "+----+\n",
      "| 208|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col('count') > 10).select(count('*').alias('haha')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b493d",
   "metadata": {},
   "source": [
    "### Count total number of flights having destination country name is United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895ef9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sum|count|\n",
      "+------+-----+\n",
      "|411352|  125|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col('DEST_COUNTRY_NAME') == 'United States').agg(sum('count').alias('sum'), count('count').alias('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e5b8b",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1761c",
   "metadata": {},
   "source": [
    "### You are asked to select only the following columns: \"video_id\", \"trending_date\", \"title\", \"views\", into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90147fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+-----+\n",
      "|video_id|trending_date|               title|views|\n",
      "+--------+-------------+--------------------+-----+\n",
      "|       1|            4|  Goodbye First Love|  560|\n",
      "|       2|            7|       Club Sandwich|  451|\n",
      "|       3|           10|      Situation, The|  773|\n",
      "|       4|            5|          Mine Games|  165|\n",
      "|       5|            4|     Laws of Gravity|  559|\n",
      "|       6|            3|Official Story, T...|  430|\n",
      "|       7|           12|          Restaurant|  940|\n",
      "|       8|            2|          Dead Birds|  613|\n",
      "|       9|            2|         Signal, The|  759|\n",
      "|      10|           11|You Were Never Lo...|  108|\n",
      "|      11|            1|        Wholly Moses|  254|\n",
      "|      12|            8|       Firehouse Dog|  316|\n",
      "|      13|            2|        House of Wax|  858|\n",
      "|      14|           11|Half Moon (a.k.a....|  934|\n",
      "|      15|            4|        Spider-Man 3|  921|\n",
      "|      16|           10|         Wall Street|  826|\n",
      "|      17|           11|Loose Change: Sec...|  173|\n",
      "|      18|            4|Other End of the ...|  512|\n",
      "|      19|            7|     Ghostbusters II|  181|\n",
      "|      20|            3|           3 Strikes|  735|\n",
      "+--------+-------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = spark.read.csv('Video_Statistics.csv', header=True, inferSchema=True)\n",
    "videoStats = dataframe.select(\"video_id\", \"trending_date\", \"title\", \"views\")\n",
    "videoStats.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff28b6",
   "metadata": {},
   "source": [
    "### Now after selecting the columns we are interested in, we would like to create a new column inside \"videoStats\" dataframe with the name \"new\" that contains the views divided by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6e917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+-----+----+\n",
      "|video_id|trending_date|               title|views| new|\n",
      "+--------+-------------+--------------------+-----+----+\n",
      "|       1|            4|  Goodbye First Love|  560| 5.6|\n",
      "|       2|            7|       Club Sandwich|  451|4.51|\n",
      "|       3|           10|      Situation, The|  773|7.73|\n",
      "|       4|            5|          Mine Games|  165|1.65|\n",
      "|       5|            4|     Laws of Gravity|  559|5.59|\n",
      "|       6|            3|Official Story, T...|  430| 4.3|\n",
      "|       7|           12|          Restaurant|  940| 9.4|\n",
      "|       8|            2|          Dead Birds|  613|6.13|\n",
      "|       9|            2|         Signal, The|  759|7.59|\n",
      "|      10|           11|You Were Never Lo...|  108|1.08|\n",
      "|      11|            1|        Wholly Moses|  254|2.54|\n",
      "|      12|            8|       Firehouse Dog|  316|3.16|\n",
      "|      13|            2|        House of Wax|  858|8.58|\n",
      "|      14|           11|Half Moon (a.k.a....|  934|9.34|\n",
      "|      15|            4|        Spider-Man 3|  921|9.21|\n",
      "|      16|           10|         Wall Street|  826|8.26|\n",
      "|      17|           11|Loose Change: Sec...|  173|1.73|\n",
      "|      18|            4|Other End of the ...|  512|5.12|\n",
      "|      19|            7|     Ghostbusters II|  181|1.81|\n",
      "|      20|            3|           3 Strikes|  735|7.35|\n",
      "+--------+-------------+--------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videoStats = videoStats.withColumn('new', col('views')/100)\n",
    "videoStats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6f925",
   "metadata": {},
   "source": [
    "### Please write the line of code to calculate the mean of the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00817628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg(views)|\n",
      "+----------+\n",
      "|     553.4|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videoStats.select(mean('views')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da42d80",
   "metadata": {},
   "source": [
    "### Please write the line of code to calculate the standard deviation of the population of the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6cb7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|Standard Deviation|\n",
      "+------------------+\n",
      "| 276.5580228451165|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videoStats.select(stddev_pop('views').alias('Standard Deviation')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899e2cc",
   "metadata": {},
   "source": [
    "### Please write the line of code to find the maximum of the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec42815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Max Views|\n",
      "+---------+\n",
      "|      940|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "videoStats.select(max('views').alias('Max Views')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07146d80",
   "metadata": {},
   "source": [
    "### Group the dataframe by the \"trending_date\" column and aggregate by the mean of the \"views\" column. The result should be put in a new dataframe named \"videoStatGroup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2732998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|trending_date|       avg(views)|\n",
      "+-------------+-----------------+\n",
      "|           12|            940.0|\n",
      "|            1|            254.0|\n",
      "|            3|            582.5|\n",
      "|            5|            165.0|\n",
      "|            4|            638.0|\n",
      "|            8|            316.0|\n",
      "|            7|            316.0|\n",
      "|           10|            799.5|\n",
      "|           11|            405.0|\n",
      "|            2|743.3333333333334|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 30:==========================================>             (57 + 8) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "videoStatGroup = videoStats.groupby('trending_date').agg(mean('views'))\n",
    "videoStatGroup.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c620fc",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "259304d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying Dataset\n",
    "dataframe = spark.read.csv('retail_data.csv', header=True, inferSchema=True)\n",
    "dataframe.createTempView('retail_data')\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e5407",
   "metadata": {},
   "source": [
    "### How many orders did customers perform at which hour? (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6047d387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|HOUR|Orders|\n",
      "+----+------+\n",
      "|  12|    23|\n",
      "|  13|    12|\n",
      "|  16|    17|\n",
      "|  15|    15|\n",
      "|   9|    18|\n",
      "|  17|     6|\n",
      "|   8|     6|\n",
      "|  10|    12|\n",
      "|  11|    13|\n",
      "|  14|    21|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select HOUR(InvoiceDate) AS HOUR, COUNT(DISTINCT(InvoiceNo)) AS Orders from retail_data group by HOUR(InvoiceDate)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6a43c",
   "metadata": {},
   "source": [
    "### How frequently was each product bought in different countries? (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c30d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----+\n",
      "|       Country|StockCode|Count|\n",
      "+--------------+---------+-----+\n",
      "|United Kingdom|    22154|    1|\n",
      "|United Kingdom|    22478|    1|\n",
      "|United Kingdom|    22844|    3|\n",
      "|United Kingdom|    22768|    4|\n",
      "|United Kingdom|    16238|    3|\n",
      "|United Kingdom|    22916|    3|\n",
      "|United Kingdom|    21704|    2|\n",
      "|United Kingdom|        M|    2|\n",
      "|United Kingdom|   35271S|    1|\n",
      "|United Kingdom|    70007|    4|\n",
      "|       Germany|    22242|    2|\n",
      "|United Kingdom|    72741|    4|\n",
      "|United Kingdom|   84534B|    1|\n",
      "|United Kingdom|    22342|    1|\n",
      "|United Kingdom|   46776B|    1|\n",
      "|United Kingdom|    21816|    1|\n",
      "|United Kingdom|    22375|    1|\n",
      "|United Kingdom|   85232B|    5|\n",
      "|United Kingdom|   84596E|    1|\n",
      "|United Kingdom|    21851|    2|\n",
      "+--------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " spark.sql(\"select Country, StockCode, Count(*) as Count from retail_data group by StockCode, Country\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae712ce9",
   "metadata": {},
   "source": [
    "### How many orders did customers perform at which hour? (Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37cd923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|HOUR|count(InvoiceNo)|\n",
      "+----+----------------+\n",
      "|  12|              23|\n",
      "|  13|              12|\n",
      "|  16|              17|\n",
      "|  15|              15|\n",
      "|   9|              18|\n",
      "|  17|               6|\n",
      "|   8|               6|\n",
      "|  10|              12|\n",
      "|  11|              13|\n",
      "|  14|              21|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(hour('InvoiceDate').alias('HOUR'), 'InvoiceNo').groupby('HOUR').agg(countDistinct('InvoiceNo')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d882a",
   "metadata": {},
   "source": [
    "### How frequently was each product bought in different countries? (Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e311a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+--------+\n",
      "|       Country|StockCode|Quantity|\n",
      "+--------------+---------+--------+\n",
      "|United Kingdom|    21125|      12|\n",
      "|United Kingdom|    21794|       1|\n",
      "|United Kingdom|    21662|       3|\n",
      "|          EIRE|   85136C|       2|\n",
      "|United Kingdom|   84032A|      22|\n",
      "|United Kingdom|   84086C|       2|\n",
      "|United Kingdom|   90214H|       2|\n",
      "|United Kingdom|    22753|       9|\n",
      "|United Kingdom|    21557|       3|\n",
      "|United Kingdom|    21743|      15|\n",
      "|United Kingdom|    22488|      12|\n",
      "|United Kingdom|    22956|       4|\n",
      "|        Norway|    22531|      24|\n",
      "|United Kingdom|    22728|      13|\n",
      "|United Kingdom|    82551|       3|\n",
      "|United Kingdom|    22581|       4|\n",
      "|United Kingdom|    21671|       2|\n",
      "|United Kingdom|   90177E|       1|\n",
      "|United Kingdom|   84926A|       4|\n",
      "|United Kingdom|    20726|       2|\n",
      "+--------------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Variant one\n",
    "dataframe.select('Country', 'StockCode', 'Quantity').groupby('Country', 'StockCode').agg(sum('Quantity').alias('Quantity')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bfe5bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+--------+\n",
      "|       Country|StockCode|Quantity|\n",
      "+--------------+---------+--------+\n",
      "|United Kingdom|    21125|      12|\n",
      "|United Kingdom|    21794|       1|\n",
      "|United Kingdom|    21662|       3|\n",
      "|          EIRE|   85136C|       2|\n",
      "|United Kingdom|   84032A|      22|\n",
      "|United Kingdom|   84086C|       2|\n",
      "|United Kingdom|   90214H|       2|\n",
      "|United Kingdom|    22753|       9|\n",
      "|United Kingdom|    21557|       3|\n",
      "|United Kingdom|    21743|      15|\n",
      "|United Kingdom|    22488|      12|\n",
      "|United Kingdom|    22956|       4|\n",
      "|        Norway|    22531|      24|\n",
      "|United Kingdom|    22728|      13|\n",
      "|United Kingdom|    82551|       3|\n",
      "|United Kingdom|    22581|       4|\n",
      "|United Kingdom|    21671|       2|\n",
      "|United Kingdom|   90177E|       1|\n",
      "|United Kingdom|   84926A|       4|\n",
      "|United Kingdom|    20726|       2|\n",
      "+--------------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variant two\n",
    "dataframe.groupby('Country', 'StockCode').agg(sum('Quantity').alias('Quantity')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec4ee8",
   "metadata": {},
   "source": [
    "### Select from a datacube a slice that contains only items from the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b4bd3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For slice operation, use where clause on only one column and NOT MORE\n",
    "dataframe.where(col(\"Country\") == \"United States\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d1b0b",
   "metadata": {},
   "source": [
    "### Dice Operation - Select a sub-cube from a datacube that contains items from United states and United Kingdom with quantities 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a95e8209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.where((col(\"Country\") == \"United States\") | (col(\"Country\") == \"United Kingdom\")).where(col(\"Quantity\") == 0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05cb02e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.where(((col(\"Country\") == \"United States\") | (col(\"Country\") == \"United Kingdom\")) & (col(\"Quantity\") == 0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f988",
   "metadata": {},
   "source": [
    "### Which of the following codes peforms a rollup from a datacube?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8327e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------------+\n",
      "|StockCode|       Country|positive quantity|\n",
      "+---------+--------------+-----------------+\n",
      "|   85123A|United Kingdom|             true|\n",
      "|    71053|United Kingdom|             true|\n",
      "|   84406B|United Kingdom|             true|\n",
      "|   84029G|United Kingdom|             true|\n",
      "|   84029E|United Kingdom|             true|\n",
      "|    22752|United Kingdom|             true|\n",
      "|    21730|United Kingdom|             true|\n",
      "|    22633|United Kingdom|             true|\n",
      "|    22632|United Kingdom|             true|\n",
      "|    84879|United Kingdom|             true|\n",
      "|    22745|United Kingdom|             true|\n",
      "|    22748|United Kingdom|             true|\n",
      "|    22749|United Kingdom|             true|\n",
      "|    22310|United Kingdom|             true|\n",
      "|    84969|United Kingdom|             true|\n",
      "|    22623|United Kingdom|             true|\n",
      "|    22622|United Kingdom|             true|\n",
      "|    21754|United Kingdom|             true|\n",
      "|    21755|United Kingdom|             true|\n",
      "|    21777|United Kingdom|             true|\n",
      "+---------+--------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(\"StockCode\", \"Country\", (col(\"Quantity\") > 0).alias(\"positive quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ed9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.where(col(\"Quantity\") > 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599e346",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ba44c",
   "metadata": {},
   "source": [
    "### How many instances of each product were sold in each country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bae7e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>22728</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country  22728\n",
       "0  France     24"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe.filter((col(\"StockCode\") == 22728) & (col(\"Country\") == \"France\")).groupBy(\"Country\").pivot(\"StockCode\").sum(\"Quantity\").toPandas()\n",
    "dataframe.filter(\"StockCode = 22728 AND Country = 'France'\").groupBy(\"Country\").pivot(\"StockCode\").sum(\"Quantity\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c047c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Australia</th>\n",
       "      <th>EIRE</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Netherlands</th>\n",
       "      <th>Norway</th>\n",
       "      <th>United Kingdom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>84906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>22492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>17164B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>22311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>85114C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1351 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     StockCode  Australia  EIRE  France  Germany  Netherlands  Norway  \\\n",
       "0        22728        NaN   NaN    24.0      NaN          NaN     NaN   \n",
       "1        21259        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "2        21889        NaN  24.0     NaN      NaN          NaN     NaN   \n",
       "3        22121        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "4        90022        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "...        ...        ...   ...     ...      ...          ...     ...   \n",
       "1346     84906        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "1347     22492        NaN  36.0    36.0      NaN          NaN     NaN   \n",
       "1348    17164B        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "1349     22311        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "1350    85114C        NaN   NaN     NaN      NaN          NaN     NaN   \n",
       "\n",
       "      United Kingdom  \n",
       "0               13.0  \n",
       "1                8.0  \n",
       "2               28.0  \n",
       "3               14.0  \n",
       "4                1.0  \n",
       "...              ...  \n",
       "1346             1.0  \n",
       "1347            36.0  \n",
       "1348             2.0  \n",
       "1349             8.0  \n",
       "1350             3.0  \n",
       "\n",
       "[1351 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.groupBy(\"StockCode\").pivot(\"Country\").sum(\"Quantity\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b5eb7",
   "metadata": {},
   "source": [
    "### Which employees could convince customers to order products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d776d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "employees = spark.read.csv('employees.csv', header=True, inferSchema=True)\n",
    "employees.createTempView('employees')\n",
    "\n",
    "customers = spark.read.csv('customers.csv', header=True, inferSchema=True)\n",
    "customers.createTempView('customers')\n",
    "\n",
    "orders = spark.read.csv('orders.csv', header=True, inferSchema=True)\n",
    "orders.createTempView('orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48d024b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>Samson Ortiz</td>\n",
       "      <td>consectetuer.cursus@utodio.net</td>\n",
       "      <td>0845 46 41</td>\n",
       "      <td>OctOct-1616-21212121</td>\n",
       "      <td>57</td>\n",
       "      <td>Lavinia Melendez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>Stephen Dejesus</td>\n",
       "      <td>quis@magnaLoremipsum.com</td>\n",
       "      <td>(01269) 774419</td>\n",
       "      <td>JunJun-2727-22222222</td>\n",
       "      <td>55</td>\n",
       "      <td>Stacy Reilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>Alvin Weiss</td>\n",
       "      <td>sociis.natoque@natoquepenatibuset.co.uk</td>\n",
       "      <td>0381 994 1063</td>\n",
       "      <td>SepSep-1313-20202020</td>\n",
       "      <td>50</td>\n",
       "      <td>Inga Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>Benjamin Reyes</td>\n",
       "      <td>Nullam.scelerisque@turpisvitae.net</td>\n",
       "      <td>076 8045 4732</td>\n",
       "      <td>FebFeb-1818-21212121</td>\n",
       "      <td>52</td>\n",
       "      <td>Libby Weeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>Amal Gross</td>\n",
       "      <td>aliquam.eu@semconsequat.net</td>\n",
       "      <td>055 1465 7860</td>\n",
       "      <td>NovNov-0707-21212121</td>\n",
       "      <td>56</td>\n",
       "      <td>Marah Dean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>Kato Hoover</td>\n",
       "      <td>sed.sem.egestas@blanditat.com</td>\n",
       "      <td>(01740) 44119</td>\n",
       "      <td>JulJul-0707-22222222</td>\n",
       "      <td>59</td>\n",
       "      <td>Macey Slater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76</td>\n",
       "      <td>Yuli Warren</td>\n",
       "      <td>nisi.nibh.lacinia@malesuada.ca</td>\n",
       "      <td>(010256) 78732</td>\n",
       "      <td>FebFeb-1515-21212121</td>\n",
       "      <td>56</td>\n",
       "      <td>Hanna Pugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77</td>\n",
       "      <td>Wade Nichols</td>\n",
       "      <td>urna.justo.faucibus@sapiencursusin.net</td>\n",
       "      <td>(023) 5115 1644</td>\n",
       "      <td>AugAug-2222-20202020</td>\n",
       "      <td>56</td>\n",
       "      <td>Gwendolyn Ramirez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78</td>\n",
       "      <td>Drake Morales</td>\n",
       "      <td>quam.elementum@ProinultricesDuis.org</td>\n",
       "      <td>07495 111025</td>\n",
       "      <td>JulJul-2828-20202020</td>\n",
       "      <td>55</td>\n",
       "      <td>Jeanette Phillips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79</td>\n",
       "      <td>Silas Barber</td>\n",
       "      <td>vitae@bibendumullamcorperDuis.com</td>\n",
       "      <td>055 5328 8347</td>\n",
       "      <td>AprApr-2222-22222222</td>\n",
       "      <td>52</td>\n",
       "      <td>Yolanda Ramirez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80</td>\n",
       "      <td>Len Chambers</td>\n",
       "      <td>augue.scelerisque@dictumcursusNunc.edu</td>\n",
       "      <td>(0116) 525 0598</td>\n",
       "      <td>JanJan-2424-22222222</td>\n",
       "      <td>60</td>\n",
       "      <td>Leandra Sampson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>81</td>\n",
       "      <td>Asher Gamble</td>\n",
       "      <td>eu.dolor.egestas@anteipsumprimis.com</td>\n",
       "      <td>056 4305 4146</td>\n",
       "      <td>MayMay-3131-21212121</td>\n",
       "      <td>57</td>\n",
       "      <td>Jada Booth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>82</td>\n",
       "      <td>Kennedy Pruitt</td>\n",
       "      <td>luctus@tellusfaucibusleo.org</td>\n",
       "      <td>0879 962 9844</td>\n",
       "      <td>MayMay-2828-22222222</td>\n",
       "      <td>59</td>\n",
       "      <td>Keiko Perkins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83</td>\n",
       "      <td>Clinton Lowery</td>\n",
       "      <td>mauris@aliquetmagnaa.org</td>\n",
       "      <td>0500 853852</td>\n",
       "      <td>MayMay-1414-21212121</td>\n",
       "      <td>51</td>\n",
       "      <td>Lillith Wong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84</td>\n",
       "      <td>Dexter Mcgowan</td>\n",
       "      <td>sem@uteros.edu</td>\n",
       "      <td>0800 598 9641</td>\n",
       "      <td>OctOct-1010-21212121</td>\n",
       "      <td>51</td>\n",
       "      <td>Ariana Bean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85</td>\n",
       "      <td>Hammett Ochoa</td>\n",
       "      <td>Nulla.tincidunt@sapienmolestieorci.ca</td>\n",
       "      <td>(015518) 84104</td>\n",
       "      <td>OctOct-2323-20202020</td>\n",
       "      <td>59</td>\n",
       "      <td>Chelsea Orr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86</td>\n",
       "      <td>Jesse Boone</td>\n",
       "      <td>dui@auctorveliteget.net</td>\n",
       "      <td>0500 197123</td>\n",
       "      <td>SepSep-1717-20202020</td>\n",
       "      <td>57</td>\n",
       "      <td>Willa Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>87</td>\n",
       "      <td>Wyatt West</td>\n",
       "      <td>pede@ipsumSuspendisse.com</td>\n",
       "      <td>0380 746 7516</td>\n",
       "      <td>MarMar-1212-21212121</td>\n",
       "      <td>53</td>\n",
       "      <td>Mari Kennedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>88</td>\n",
       "      <td>Gavin Munoz</td>\n",
       "      <td>habitant.morbi.tristique@libero.ca</td>\n",
       "      <td>0955 043 7574</td>\n",
       "      <td>FebFeb-1616-21212121</td>\n",
       "      <td>53</td>\n",
       "      <td>Jasmine Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>89</td>\n",
       "      <td>Basil Little</td>\n",
       "      <td>at@sitametconsectetuer.edu</td>\n",
       "      <td>0500 858869</td>\n",
       "      <td>OctOct-1515-20202020</td>\n",
       "      <td>51</td>\n",
       "      <td>Jenette Gentry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id             Name                                    email  \\\n",
       "0            70     Samson Ortiz           consectetuer.cursus@utodio.net   \n",
       "1            71  Stephen Dejesus                 quis@magnaLoremipsum.com   \n",
       "2            72      Alvin Weiss  sociis.natoque@natoquepenatibuset.co.uk   \n",
       "3            73   Benjamin Reyes       Nullam.scelerisque@turpisvitae.net   \n",
       "4            74       Amal Gross              aliquam.eu@semconsequat.net   \n",
       "5            75      Kato Hoover            sed.sem.egestas@blanditat.com   \n",
       "6            76      Yuli Warren           nisi.nibh.lacinia@malesuada.ca   \n",
       "7            77     Wade Nichols   urna.justo.faucibus@sapiencursusin.net   \n",
       "8            78    Drake Morales     quam.elementum@ProinultricesDuis.org   \n",
       "9            79     Silas Barber        vitae@bibendumullamcorperDuis.com   \n",
       "10           80     Len Chambers   augue.scelerisque@dictumcursusNunc.edu   \n",
       "11           81     Asher Gamble     eu.dolor.egestas@anteipsumprimis.com   \n",
       "12           82   Kennedy Pruitt             luctus@tellusfaucibusleo.org   \n",
       "13           83   Clinton Lowery                 mauris@aliquetmagnaa.org   \n",
       "14           84   Dexter Mcgowan                           sem@uteros.edu   \n",
       "15           85    Hammett Ochoa    Nulla.tincidunt@sapienmolestieorci.ca   \n",
       "16           86      Jesse Boone                  dui@auctorveliteget.net   \n",
       "17           87       Wyatt West                pede@ipsumSuspendisse.com   \n",
       "18           88      Gavin Munoz       habitant.morbi.tristique@libero.ca   \n",
       "19           89     Basil Little               at@sitametconsectetuer.edu   \n",
       "\n",
       "              phone             hire_date  manager_id          job_title  \n",
       "0        0845 46 41  OctOct-1616-21212121          57   Lavinia Melendez  \n",
       "1    (01269) 774419  JunJun-2727-22222222          55       Stacy Reilly  \n",
       "2     0381 994 1063  SepSep-1313-20202020          50          Inga Snow  \n",
       "3     076 8045 4732  FebFeb-1818-21212121          52        Libby Weeks  \n",
       "4     055 1465 7860  NovNov-0707-21212121          56         Marah Dean  \n",
       "5     (01740) 44119  JulJul-0707-22222222          59       Macey Slater  \n",
       "6    (010256) 78732  FebFeb-1515-21212121          56         Hanna Pugh  \n",
       "7   (023) 5115 1644  AugAug-2222-20202020          56  Gwendolyn Ramirez  \n",
       "8      07495 111025  JulJul-2828-20202020          55  Jeanette Phillips  \n",
       "9     055 5328 8347  AprApr-2222-22222222          52    Yolanda Ramirez  \n",
       "10  (0116) 525 0598  JanJan-2424-22222222          60    Leandra Sampson  \n",
       "11    056 4305 4146  MayMay-3131-21212121          57         Jada Booth  \n",
       "12    0879 962 9844  MayMay-2828-22222222          59      Keiko Perkins  \n",
       "13      0500 853852  MayMay-1414-21212121          51       Lillith Wong  \n",
       "14    0800 598 9641  OctOct-1010-21212121          51        Ariana Bean  \n",
       "15   (015518) 84104  OctOct-2323-20202020          59        Chelsea Orr  \n",
       "16      0500 197123  SepSep-1717-20202020          57     Willa Anderson  \n",
       "17    0380 746 7516  MarMar-1212-21212121          53       Mari Kennedy  \n",
       "18    0955 043 7574  FebFeb-1616-21212121          53       Jasmine Cash  \n",
       "19      0500 858869  OctOct-1515-20202020          51     Jenette Gentry  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have used toPandas() here for beauty only. In exams, it should be show() instead.\n",
    "spark.sql(\"SELECT * FROM employees e LEFT SEMI JOIN orders o ON e.employee_id = o.salesman_id\").toPandas()\n",
    "# employees.join(orders, expr(\"employee_id = salesman_id\"), \"left_semi\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75157c90",
   "metadata": {},
   "source": [
    "### Which employees could convince most customers to order products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aa5004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id  sales\n",
       "0            83      9\n",
       "1            84      8\n",
       "2            76      7\n",
       "3            79      7\n",
       "4            72      6\n",
       "5            87      6\n",
       "6            82      6\n",
       "7            80      6\n",
       "8            89      6\n",
       "9            86      5\n",
       "10           73      5\n",
       "11           71      5\n",
       "12           85      4\n",
       "13           77      4\n",
       "14           70      4\n",
       "15           81      3\n",
       "16           75      3\n",
       "17           74      3\n",
       "18           78      2\n",
       "19           88      1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OF COURSE YOU SHOULD RUN EITHER OF THEM AND COMMENT OUT THE OTHER ONE\n",
    "\n",
    "# Note the expr() function used in agg. It is simply sql representation of the same statement\n",
    "employees.join(orders, expr(\"employee_id = salesman_id\"),\"inner\") \\\n",
    ".groupBy(\"employee_id\").agg(expr(\"count(*) AS sales\")).orderBy(\"sales\",ascending=False).toPandas()\n",
    "\n",
    "# expr() functions equivalent query using dataframe at agg.\n",
    "employees.join(orders, expr(\"employee_id = salesman_id\"),\"inner\") \\\n",
    ".groupBy(\"employee_id\").agg(count('*').alias('sales')).orderBy(\"sales\",ascending=False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "779d5b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id  sales\n",
       "0            83      9\n",
       "1            84      8\n",
       "2            76      7\n",
       "3            79      7\n",
       "4            72      6\n",
       "5            87      6\n",
       "6            82      6\n",
       "7            80      6\n",
       "8            89      6\n",
       "9            86      5\n",
       "10           73      5\n",
       "11           71      5\n",
       "12           85      4\n",
       "13           77      4\n",
       "14           70      4\n",
       "15           81      3\n",
       "16           75      3\n",
       "17           74      3\n",
       "18           78      2\n",
       "19           88      1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same query as above using spark SQL\n",
    "spark.sql(\"SELECT e.employee_id, count(*) as sales FROM employees e INNER JOIN orders o ON e.employee_id = o.salesman_id GROUP BY e.employee_id ORDER BY sales DESC\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d0cf3",
   "metadata": {},
   "source": [
    "# Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d7ec4",
   "metadata": {},
   "source": [
    "### Use the RDD API to identify how many orders each customer is waiting for (this means, status = \"Pending\"). The customers are identified only by customer id. Sort the resulting RDD by the number of pending orders in descending order. The variable orders is a reference to the DataFrame Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5c4735e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(55, 3), (56, 3), (63, 2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.rdd.filter(lambda row: row[\"status\"] == \"hall\") \\\n",
    ".map(lambda row: (row[\"customer_id\"], 1)).reduceByKey(lambda x,y: x+y) \\\n",
    ".sortBy(lambda x:x[1], ascending=False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea01e4",
   "metadata": {},
   "source": [
    "# Assignment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948f4fe",
   "metadata": {},
   "source": [
    "### Naive Bayes - Use a Naive Bayes classifier to predict whether you should play tennis when it is (rainy, hot, not windy, and humidity normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f477f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('weather.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32a8989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021164021164021163"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of YES\n",
    "\n",
    "# P(yes | rainy, hot, normal, not windy)\n",
    "# = P(yes) * P(rainy | yes) * P(hot | yes) * P(normal | yes) * P(not windy | yes)\n",
    "count_yes = df.where(\"Play = 'YES'\").count()\n",
    "p_yes = count_yes / df.count()\n",
    "p_rainy_yes = df.where(\"Outlook = 'rainy' AND Play = 'YES'\").count() / count_yes\n",
    "p_hot_yes = df.where(\"Temperature = 'hot' AND Play = 'YES'\").count() / count_yes\n",
    "p_normal_yes = df.where(\"Humidity = 'normal' AND Play = 'YES'\").count() / count_yes\n",
    "p_windy_yes = df.where(\"Windy = False AND Play = 'YES'\").count() / count_yes\n",
    "\n",
    "probability_yes = p_yes * p_rainy_yes * p_hot_yes * p_normal_yes * p_windy_yes\n",
    "probability_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc71d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004571428571428573"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of NO\n",
    "\n",
    "# P(no | rainy, hot, normal, not windy)\n",
    "# P(no) * P(rainy | no) * P(hot | no) * P(normal | no) * P(not windy | no)\n",
    "\n",
    "count_no = df.where(\"Play = 'NO'\").count()\n",
    "p_no = count_no / df.count()\n",
    "p_rainy_no = df.where(\"Outlook = 'rainy' AND Play = 'NO'\").count() / count_no\n",
    "p_hot_no = df.where(\"Temperature = 'hot' AND Play = 'NO'\").count() / count_no\n",
    "p_normal_no = df.where(\"Humidity = 'normal' AND Play = 'NO'\").count() / count_no\n",
    "p_windy_no = df.where(\"Windy = False AND Play = 'NO'\").count() / count_no\n",
    "probability_no = p_no * p_rainy_no * p_hot_no * p_normal_no * p_windy_no\n",
    "probability_no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3a1c8",
   "metadata": {},
   "source": [
    "### Logistic Regression - Spark Classifier - Please classify the following animals into either a Mammal or not a Mammal after apply a logistic regression on the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c64ab16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+\n",
      "|AnimalName|IsMammal|prediction|\n",
      "+----------+--------+----------+\n",
      "|  aardvark|       1|       1.0|\n",
      "|  antelope|       1|       1.0|\n",
      "|      bass|       0|       0.0|\n",
      "|      bear|       1|       1.0|\n",
      "|      boar|       1|       1.0|\n",
      "|   buffalo|       1|       1.0|\n",
      "|      calf|       1|       1.0|\n",
      "|      carp|       0|       0.0|\n",
      "|   catfish|       0|       0.0|\n",
      "|      cavy|       1|       1.0|\n",
      "|   cheetah|       1|       1.0|\n",
      "|   chicken|       0|       0.0|\n",
      "|      chub|       0|       0.0|\n",
      "|      clam|       0|       0.0|\n",
      "|      crab|       0|       0.0|\n",
      "|  crayfish|       0|       0.0|\n",
      "|      crow|       0|       0.0|\n",
      "|      deer|       1|       1.0|\n",
      "|   dogfish|       0|       0.0|\n",
      "|   dolphin|       1|       1.0|\n",
      "|      dove|       0|       0.0|\n",
      "|      duck|       0|       0.0|\n",
      "|  elephant|       1|       1.0|\n",
      "|  flamingo|       0|       0.0|\n",
      "|      flea|       0|       0.0|\n",
      "|      frog|       0|       0.0|\n",
      "|      frog|       0|       0.0|\n",
      "|  fruitbat|       1|       1.0|\n",
      "|   giraffe|       1|       1.0|\n",
      "|      girl|       1|       1.0|\n",
      "|      gnat|       0|       0.0|\n",
      "|      goat|       1|       1.0|\n",
      "|   gorilla|       1|       1.0|\n",
      "|      gull|       0|       0.0|\n",
      "|   haddock|       0|       0.0|\n",
      "|   hamster|       1|       1.0|\n",
      "|      hare|       1|       1.0|\n",
      "|      hawk|       0|       0.0|\n",
      "|   herring|       0|       0.0|\n",
      "|  honeybee|       0|       0.0|\n",
      "|  housefly|       0|       0.0|\n",
      "|      kiwi|       0|       0.0|\n",
      "|  ladybird|       0|       0.0|\n",
      "|      lark|       0|       0.0|\n",
      "|   leopard|       1|       1.0|\n",
      "|      lion|       1|       1.0|\n",
      "|   lobster|       0|       0.0|\n",
      "|      lynx|       1|       1.0|\n",
      "|      mink|       1|       1.0|\n",
      "|      mole|       1|       1.0|\n",
      "|  mongoose|       1|       1.0|\n",
      "|      moth|       0|       0.0|\n",
      "|      newt|       0|       0.0|\n",
      "|   octopus|       0|       0.0|\n",
      "|   opossum|       1|       1.0|\n",
      "|      oryx|       1|       1.0|\n",
      "|   ostrich|       0|       0.0|\n",
      "|  parakeet|       0|       0.0|\n",
      "|   penguin|       0|       0.0|\n",
      "|  pheasant|       0|       0.0|\n",
      "|      pike|       0|       0.0|\n",
      "|   piranha|       0|       0.0|\n",
      "|  pitviper|       0|       0.0|\n",
      "|  platypus|       1|       1.0|\n",
      "|   polecat|       1|       1.0|\n",
      "|      pony|       1|       1.0|\n",
      "|  porpoise|       1|       1.0|\n",
      "|      puma|       1|       1.0|\n",
      "|  pussycat|       1|       1.0|\n",
      "|   raccoon|       1|       1.0|\n",
      "|  reindeer|       1|       1.0|\n",
      "|      rhea|       0|       0.0|\n",
      "|  scorpion|       0|       0.0|\n",
      "|  seahorse|       0|       0.0|\n",
      "|      seal|       1|       1.0|\n",
      "|   sealion|       1|       1.0|\n",
      "|  seasnake|       0|       0.0|\n",
      "|   seawasp|       0|       0.0|\n",
      "|   skimmer|       0|       0.0|\n",
      "|      skua|       0|       0.0|\n",
      "|  slowworm|       0|       0.0|\n",
      "|      slug|       0|       0.0|\n",
      "|      sole|       0|       0.0|\n",
      "|   sparrow|       0|       0.0|\n",
      "|  squirrel|       1|       1.0|\n",
      "|  starfish|       0|       0.0|\n",
      "|  stingray|       0|       0.0|\n",
      "|      swan|       0|       0.0|\n",
      "|   termite|       0|       0.0|\n",
      "|      toad|       0|       0.0|\n",
      "|  tortoise|       0|       0.0|\n",
      "|   tuatara|       0|       0.0|\n",
      "|      tuna|       0|       0.0|\n",
      "|   vampire|       1|       1.0|\n",
      "|      vole|       1|       1.0|\n",
      "|   vulture|       0|       0.0|\n",
      "|   wallaby|       1|       1.0|\n",
      "|      wasp|       0|       0.0|\n",
      "|      wolf|       1|       1.0|\n",
      "|      worm|       0|       0.0|\n",
      "|      wren|       0|       0.0|\n",
      "+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the ZOO dataset:\n",
    "zoo_data=spark.read.csv(\"zoo.csv\",inferSchema=True,header=True)\n",
    "zoo_data = zoo_data.withColumn(\"IsMammal\", expr(\"CASE WHEN Type = 1 THEN 1 ELSE 0 END\"))\n",
    "\n",
    "# preprocess dataset using RFormula\n",
    "preprocessed_data = RFormula(formula= \"IsMammal ~ Hair + Feathers + Eggs + Milk + Airborne + Aquatic +\" + \n",
    "                             \" Predator + Toothed + Backbone + Venomous + Fins + Legs+\" +\n",
    "                            \"Tail + Domestic + Catsize\")\n",
    "\n",
    "preprocessed_data = preprocessed_data.fit(zoo_data)\n",
    "preprocessed_data = preprocessed_data.transform(zoo_data)\n",
    "\n",
    "# split dataset into training and test data\n",
    "train, test = preprocessed_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# configure classifier\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# train classifier\n",
    "fittedLR = lr.fit(train)\n",
    "\n",
    "# classify test data set\n",
    "result = fittedLR.transform(preprocessed_data)\n",
    "\n",
    "# Displaying only the prediction of selected animals\n",
    "result.select('AnimalName', 'label', 'prediction').where(expr(\"AnimalName in ('lobster', 'hawk', 'goat', 'crayfish', 'clam', 'hamster')\")).toPandas()\n",
    "\n",
    "# Printing all\n",
    "result_extracted = result.select(\"AnimalName\", \"IsMammal\", \"prediction\")\n",
    "result_extracted.show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d24aa",
   "metadata": {},
   "source": [
    "# Assignment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa3e4e",
   "metadata": {},
   "source": [
    "### Gussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90ecf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Yes:  76.16666666666667\n",
      "Var Yes:  267.76666666666665\n",
      "Mean No:  29.8\n",
      "Var No:  131.69999999999996\n",
      "P(61|yes):  0.01586679399696767\n",
      "P(61|No):  0.0008631916482906201\n",
      "P(yes|61):  0.0265\n",
      "P(No|61):  0.00018\n"
     ]
    }
   ],
   "source": [
    "alice = Row(student=\"Alice\", percent_achieved = 70, pass_exam = \"Yes\")\n",
    "bob = Row(student=\"Bob\", percent_achieved = 36, pass_exam = \"No\")\n",
    "carol = Row(student=\"Carol\", percent_achieved = 95, pass_exam = \"Yes\")\n",
    "dan = Row(student=\"Dan\", percent_achieved = 63, pass_exam = \"Yes\")\n",
    "eve = Row(student=\"Eve\", percent_achieved = 43, pass_exam = \"No\")\n",
    "frank = Row(student=\"Frank\", percent_achieved = 84, pass_exam = \"Yes\")\n",
    "grace = Row(student=\"Grace\", percent_achieved = 54, pass_exam = \"Yes\")\n",
    "heidi = Row(student=\"Heidi\", percent_achieved = 15, pass_exam = \"No\")\n",
    "ivan = Row(student=\"Ivan\", percent_achieved = 21, pass_exam = \"No\")\n",
    "judy = Row(student=\"Judy\", percent_achieved = 91, pass_exam = \"Yes\")\n",
    "mallory = Row(student=\"Mallory\", percent_achieved = 34, pass_exam = \"No\")\n",
    "\n",
    "dataTable = [alice,bob,carol,dan,eve,frank,grace,heidi,ivan,judy,mallory]\n",
    "df = spark.createDataFrame(dataTable)\n",
    "\n",
    "df_yes = df.where(col(\"pass_exam\")==\"Yes\")\n",
    "df_no =df.where(col(\"pass_exam\")==\"No\")\n",
    "\n",
    "mean_yes = df_yes.select(mean(\"percent_achieved\")).first()[0]\n",
    "mean_no = df_no.select(mean(\"percent_achieved\")).first()[0]\n",
    "\n",
    "stddev_yes = df_yes.select(stddev(\"percent_achieved\")).first()[0]\n",
    "var_yes = stddev_yes * stddev_yes\n",
    "\n",
    "stddev_no = df_no.select(stddev(\"percent_achieved\")).first()[0]\n",
    "var_no = stddev_no * stddev_no\n",
    "\n",
    "print(\"Mean Yes: \", mean_yes)\n",
    "print(\"Var Yes: \",var_yes)\n",
    "print(\"Mean No: \",mean_no)\n",
    "print(\"Var No: \",var_no)\n",
    "\n",
    "def gaus(x,mean, variance):\n",
    "    return (1/(math.sqrt(2*math.pi*variance)))*math.exp(-((61-mean)**2)/(2*variance))\n",
    "\n",
    "print(\"P(61|yes): \",gaus(61,mean_yes,var_yes))\n",
    "print(\"P(61|No): \",gaus(61,mean_no,var_no))\n",
    "\n",
    "print(\"P(yes|61): \", (1/6)*0.159)\n",
    "print(\"P(No|61): \", (1/5)*0.0009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b373b96f",
   "metadata": {},
   "source": [
    "# Assignment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55af1488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2021-07-21 08:00:00, 2021-07-21 08:15:00)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2021-07-21 08:20:00, 2021-07-21 08:35:00)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2021-07-21 08:10:00, 2021-07-21 08:25:00)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2021-07-21 08:40:00, 2021-07-21 08:55:00)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2021-07-21 08:30:00, 2021-07-21 08:45:00)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2021-07-21 07:50:00, 2021-07-21 08:05:00)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       window  count\n",
       "0  (2021-07-21 08:00:00, 2021-07-21 08:15:00)      2\n",
       "1  (2021-07-21 08:20:00, 2021-07-21 08:35:00)      4\n",
       "2  (2021-07-21 08:10:00, 2021-07-21 08:25:00)      3\n",
       "3  (2021-07-21 08:40:00, 2021-07-21 08:55:00)      1\n",
       "4  (2021-07-21 08:30:00, 2021-07-21 08:45:00)      3\n",
       "5  (2021-07-21 07:50:00, 2021-07-21 08:05:00)      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming = spark.read.csv('windowing.csv', inferSchema=True, header=True)\n",
    "withEventTime = streaming.groupBy(window(col(\"Time\"), \"15 minutes\", \"10 minutes\")).count()\n",
    "withEventTime.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db846503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Entering/Leaving: string (nullable = true)\n",
      " |-- Number of Persons: integer (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "withEventTime = streaming.selectExpr(\"*\", \"cast(cast(Time as double)/1000000000\" + \" as timestamp) as event_time\")\n",
    "# withEventTime.withWatermark(\"event_time\", \"5 seconds\").show()\n",
    "withEventTime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c239f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
